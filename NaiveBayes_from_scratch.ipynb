{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bayes from Scratch - Bag of Words ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       7.8.0 (need at least 1.0)\n",
      "Numpy version:        1.16.5 (need at least 1.7.1)\n",
      "SciPy version:         1.3.1 (need at least 0.12.0)\n",
      "Pandas version:       0.25.1 (need at least 0.11.0)\n",
      "Mapltolib version:     3.1.1 (need at least 1.2.1)\n",
      "Scikit-Learn version: 0.21.3 (need at least 0.13.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print( \"IPython version:      %6.6s (need at least 1.0)\" % IPython.__version__)\n",
    "\n",
    "# Numpy is a library for working with arrays and matrices\n",
    "import numpy as np\n",
    "print( \"Numpy version:        %6.6s (need at least 1.7.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print( \"SciPy version:        %6.6s (need at least 0.12.0)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print( \"Pandas version:       %6.6s (need at least 0.11.0)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib.pyplot as plt  \n",
    "from pylab import *\n",
    "print( \"Mapltolib version:    %6.6s (need at least 1.2.1)\" %\n",
    "       matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "# necessary for in-line graphics\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print( \"Scikit-Learn version: %6.6s (need at least 0.13.1)\" %\n",
    "       sklearn.__version__)\n",
    "import os\n",
    "# for certain system-related functions\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore and clean the data\n",
    "#### First, let's load data and take a closer look at it.\n",
    "#### 1. Take a look at a few lines of data (you may use pd.sample for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "rotten_tomatoe = pd.read_csv(\"C:\\\\Users\\\\Subhiksha\\\\Desktop\\\\574\\\\rotten-tomatoes.csv\\\\rotten-tomatoes.csv\" , sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12022</td>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>fresh</td>\n",
       "      <td>80453</td>\n",
       "      <td>http://www.variety.com/review/VE1117789400.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>Their romance is enhanced by Nestor Almendros'...</td>\n",
       "      <td>2008-07-22 00:00:00</td>\n",
       "      <td>14153</td>\n",
       "      <td>The Blue Lagoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2172</td>\n",
       "      <td>Brian Lowry</td>\n",
       "      <td>rotten</td>\n",
       "      <td>109891</td>\n",
       "      <td>http://www.variety.com/review/VE1117902805.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>Neither Macaulay Culkin nor Ted Danson has imp...</td>\n",
       "      <td>2010-07-06 00:00:00</td>\n",
       "      <td>12618</td>\n",
       "      <td>Getting Even With Dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5002</td>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>fresh</td>\n",
       "      <td>80455</td>\n",
       "      <td>http://www.variety.com/review/VE1117789404.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>Given all the chaos, director and, with Aykroy...</td>\n",
       "      <td>2008-04-01 00:00:00</td>\n",
       "      <td>13659</td>\n",
       "      <td>The Blues Brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3113</td>\n",
       "      <td>Kenneth Turan</td>\n",
       "      <td>fresh</td>\n",
       "      <td>117998</td>\n",
       "      <td>http://www.calendarlive.com/movies/reviews/cl-...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>An expert in making audiences squirm and twist...</td>\n",
       "      <td>2001-02-14 00:00:00</td>\n",
       "      <td>12652</td>\n",
       "      <td>Twister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>rotten</td>\n",
       "      <td>269347</td>\n",
       "      <td>http://www.reelviews.net/movies/h/hunted2003.html</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>This is schlock -- by-the-numbers action that ...</td>\n",
       "      <td>2003-03-16 00:00:00</td>\n",
       "      <td>13646</td>\n",
       "      <td>The Hunted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11476</td>\n",
       "      <td>Desson Thomson</td>\n",
       "      <td>rotten</td>\n",
       "      <td>116477</td>\n",
       "      <td>http://www.washingtonpost.com/wp-srv/style/lon...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>There are many ... instances when you want to ...</td>\n",
       "      <td>2002-09-25 00:00:00</td>\n",
       "      <td>12690</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>96316</td>\n",
       "      <td>http://www.timeout.com/film/reviews/79853/tuck...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>The cinematic sleight-of-hand parallels the bo...</td>\n",
       "      <td>2006-02-09 00:00:00</td>\n",
       "      <td>10430</td>\n",
       "      <td>Tucker: The Man and His Dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10661</td>\n",
       "      <td>Eleanor Ringel Gillespie</td>\n",
       "      <td>rotten</td>\n",
       "      <td>162973</td>\n",
       "      <td>http://www.accessatlanta.com/movies/content/sh...</td>\n",
       "      <td>Atlanta Journal-Constitution</td>\n",
       "      <td>The movie bravely goes where too many other fi...</td>\n",
       "      <td>2004-02-21 00:00:00</td>\n",
       "      <td>13672</td>\n",
       "      <td>Get Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6937</td>\n",
       "      <td>Stephen Holden</td>\n",
       "      <td>fresh</td>\n",
       "      <td>118901</td>\n",
       "      <td>http://movies.nytimes.com/movie/review?res=9A0...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>...the performances are juicy and intelligent.</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>15672</td>\n",
       "      <td>Critical Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8365</td>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>fresh</td>\n",
       "      <td>97757</td>\n",
       "      <td>http://www.reelviews.net/php_review_template.p...</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>A fantastic success.</td>\n",
       "      <td>2008-06-10 00:00:00</td>\n",
       "      <td>9373</td>\n",
       "      <td>The Little Mermaid 3D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         critic   fresh    imdb  \\\n",
       "12022             Variety Staff   fresh   80453   \n",
       "2172                Brian Lowry  rotten  109891   \n",
       "5002              Variety Staff   fresh   80455   \n",
       "3113              Kenneth Turan   fresh  117998   \n",
       "1150         James Berardinelli  rotten  269347   \n",
       "11476            Desson Thomson  rotten  116477   \n",
       "1054                        NaN    none   96316   \n",
       "10661  Eleanor Ringel Gillespie  rotten  162973   \n",
       "6937             Stephen Holden   fresh  118901   \n",
       "8365         James Berardinelli   fresh   97757   \n",
       "\n",
       "                                                    link  \\\n",
       "12022  http://www.variety.com/review/VE1117789400.htm...   \n",
       "2172   http://www.variety.com/review/VE1117902805.htm...   \n",
       "5002   http://www.variety.com/review/VE1117789404.htm...   \n",
       "3113   http://www.calendarlive.com/movies/reviews/cl-...   \n",
       "1150   http://www.reelviews.net/movies/h/hunted2003.html   \n",
       "11476  http://www.washingtonpost.com/wp-srv/style/lon...   \n",
       "1054   http://www.timeout.com/film/reviews/79853/tuck...   \n",
       "10661  http://www.accessatlanta.com/movies/content/sh...   \n",
       "6937   http://movies.nytimes.com/movie/review?res=9A0...   \n",
       "8365   http://www.reelviews.net/php_review_template.p...   \n",
       "\n",
       "                        publication  \\\n",
       "12022                       Variety   \n",
       "2172                        Variety   \n",
       "5002                        Variety   \n",
       "3113              Los Angeles Times   \n",
       "1150                      ReelViews   \n",
       "11476               Washington Post   \n",
       "1054                       Time Out   \n",
       "10661  Atlanta Journal-Constitution   \n",
       "6937                 New York Times   \n",
       "8365                      ReelViews   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "12022  Their romance is enhanced by Nestor Almendros'...  2008-07-22 00:00:00   \n",
       "2172   Neither Macaulay Culkin nor Ted Danson has imp...  2010-07-06 00:00:00   \n",
       "5002   Given all the chaos, director and, with Aykroy...  2008-04-01 00:00:00   \n",
       "3113   An expert in making audiences squirm and twist...  2001-02-14 00:00:00   \n",
       "1150   This is schlock -- by-the-numbers action that ...  2003-03-16 00:00:00   \n",
       "11476  There are many ... instances when you want to ...  2002-09-25 00:00:00   \n",
       "1054   The cinematic sleight-of-hand parallels the bo...  2006-02-09 00:00:00   \n",
       "10661  The movie bravely goes where too many other fi...  2004-02-21 00:00:00   \n",
       "6937      ...the performances are juicy and intelligent.  2000-01-01 00:00:00   \n",
       "8365                                A fantastic success.  2008-06-10 00:00:00   \n",
       "\n",
       "        rtid                          title  \n",
       "12022  14153                The Blue Lagoon  \n",
       "2172   12618          Getting Even With Dad  \n",
       "5002   13659             The Blues Brothers  \n",
       "3113   12652                        Twister  \n",
       "1150   13646                     The Hunted  \n",
       "11476  12690                         Hamlet  \n",
       "1054   10430  Tucker: The Man and His Dream  \n",
       "10661  13672                       Get Real  \n",
       "6937   15672                  Critical Care  \n",
       "8365    9373          The Little Mermaid 3D  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at 10 random lines of the dataset\n",
    "rotten_tomatoe.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. print out all variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['critic', 'fresh', 'imdb', 'link', 'publication', 'quote',\n",
       "       'review_date', 'rtid', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing out all variable names.\n",
    "rotten_tomatoe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a summary table (maybe more like a bullet list) where you print out the most important summary statistics for the most interesting variables. The most interesting facts you should present should include: \n",
    "* a) number of missings for fresh and quote; \n",
    "* b) all different values for fresh/rotten evaluations; \n",
    "* c) counts or percentages of these values; \n",
    "* d) number of zero-length or only whitespace quotes; \n",
    "* e) minimum-maximum-average length of quotes (either in words, or in characters). (Can you do this as an one-liner?); \n",
    "* f) how many reviews are in data multiple times. Feel free to add more figures you consider relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) number of missings for fresh and quote;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in column fresh  0\n",
      "Missing values in  column quote  0\n"
     ]
    }
   ],
   "source": [
    "# Looking at the missing values in the column fresh and quote\n",
    "print(\"Missing values in column fresh \", rotten_tomatoe['fresh'].isnull().sum())\n",
    "print(\"Missing values in  column quote \", rotten_tomatoe['quote'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) all different values for fresh/rotten evaluations;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fresh', 'rotten', 'none'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for different values for fresh/rotten evaluation\n",
    "rotten_tomatoe['fresh'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the rows with value 'none'\n",
    "rotten_tomatoe.drop(rotten_tomatoe[rotten_tomatoe['fresh'] == \"none\"].index, inplace = True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) counts or percentages of these values;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique values in the column fresh\n",
      "\n",
      "\n",
      "fresh     8389\n",
      "rotten    5030\n",
      "Name: fresh, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of unique values in the column fresh\")\n",
    "print(\"\\n\")\n",
    "print(rotten_tomatoe['fresh'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) number of zero-length or only whitespace quotes;**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of whitespaces :  0\n"
     ]
    }
   ],
   "source": [
    "# Looking for number of zero length or only whitespaces in the quote column \n",
    "\n",
    "val1 = rotten_tomatoe['quote'].astype(str).str.isspace().sum()\n",
    "print(\" Number of whitespaces : \" , val1 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) minimum-maximum-average length of quotes (either in words, or in characters). (Can you do this as an one-liner?);**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum length of quotes is : 4, the maximum length of quotes is  256 and the average length of quotes is 121.24569640062597\n"
     ]
    }
   ],
   "source": [
    "#RT_df.columns[RT_df.isna().any()].tolist()\n",
    "# field_length = RT_df.quote.astype(str).map(len)\n",
    "# print (RT_df['quote'].loc[field_length.argmin()])\n",
    "\n",
    "print('The minimum length of quotes is : ' +str(rotten_tomatoe['quote'].str.len().min()) + ', the maximum length of quotes is  ' + str(rotten_tomatoe['quote'].str.len().max()) + ' and the average length of quotes is ' +  str(rotten_tomatoe['quote'].str.len().mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) how many reviews are in data multiple times. Feel free to add more figures you consider relevant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of reviews having data multiple times :  596\n"
     ]
    }
   ],
   "source": [
    "# how many reviews are in data multiple times\n",
    "\n",
    "# keep first duplicate row\n",
    "result_df = rotten_tomatoe.drop_duplicates()\n",
    "result_df.shape[0]\n",
    "\n",
    "print(\" Number of reviews having data multiple times : \" , rotten_tomatoe.shape[0] - result_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Now when you have an overview what you have in data, clean it by removing all the inconsistencies the table reveals. We have to ensure that the central variables, quote and fresh are not missing, quote is not an empty string (or just contain spaces and such), and all rows are unique.\n",
    "#### I recommend to do it as a standalone function so you can use the same function for another similar dataset (such as test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standalone function\n",
    "def CheckInconsistency (dataset,variable1, variable2):\n",
    "    # check if variable 1 and variable 2 are not missing.\n",
    "    #print(variable1)\n",
    "    if ((dataset[variable1].isna().sum()>0 ) | (dataset[variable1].isnull().sum()>0) |(dataset[variable2].isna().sum()>0 )|(dataset[variable2].isnull().sum()>0)):\n",
    "        print('There are inconsistencies. hence dropping the null and NA values.')\n",
    "        dataset=dataset[variable1].dropna()\n",
    "        dataset=dataset[variable2].dropna()\n",
    "    else:\n",
    "        print('There are no inconsistencies in '+ variable1 + ' and ' + variable2 + ' columns')\n",
    "    \n",
    "    #check if quote is not an empty string\n",
    "    if ((dataset[variable1].empty == True) | ((dataset[variable1]== '').sum()>0) | (dataset[variable1].astype(str).str.isspace().sum())):\n",
    "        print('There are empty syring values ')\n",
    "        \n",
    "        a=dataset[dataset[variable1]==''].index\n",
    "        dataset.drop(dataset.index(a))\n",
    "    else:\n",
    "        print('There are no empty values ')\n",
    "    \n",
    "    #Drop the duplicate values\n",
    "    \n",
    "    # keep first duplicate row\n",
    "    dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no inconsistencies in quote and fresh columns\n",
      "There are no empty values \n"
     ]
    }
   ],
   "source": [
    "CheckInconsistency(result_df,'quote','fresh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now where you are familiar with the data, it's time to get serious and implement the Naive Bayes classifier from scratch. But first things first.\n",
    "#### 1. Ensure you are familiar with Naive Bayes. Consult the readings, available on canvas. Schutt & O'Neill is an easy and accessible (and long) introduction, Whitten & Frank is a lot shorter but still accessible introduction. The Lecture notes contains examples how to create baf-of-words (BOW), and how to compute Naive Bayes classifier using BOW-s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "On inspecting the data, and before we create bag-of-words, we see that in our predictor variable (column 'quote'), apart from the actual text that we require for examining and prediction, there are punctuation marks, stopwords (such as a, the , etc), and numeric values which can be ommited out of the data, for better prediction. Hence, we create a function to remove those words from any dataset, in other words implement pre processing on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into train and test\n",
    "index = int(0.8 * len(result_df))\n",
    "df_train = result_df[:index]\n",
    "df_test = result_df[index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Pre-processing \n",
    "\n",
    "def preprocessingText(result_df):\n",
    "    \n",
    "    #converting the text to lowercase for uniformity.\n",
    "    result_df['quote'] = ( result_df['quote'].apply(lambda x: \" \".join(x.lower() for x in x.split()))) # everything to lowercase\n",
    "    # removes punctuation\n",
    "    result_df['quote'] =  result_df['quote'].str.replace('[^\\w\\s]','') \n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    result_df['quote'] =  result_df['quote'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    \n",
    "            \n",
    "#     from string import punctuation\n",
    "#     for i in range(len(result_df)):\n",
    "#         result_df['quote'] = ' '.join(word.strip(punctuation) for word in result_df[i]['quote'].split() if word.strip(punctuation))\n",
    "#         #z.append(z)\n",
    "    \n",
    "    \n",
    "    return  result_df\n",
    "   \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Subhiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>ingenious concept design execution could watch...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>years inventive comedy</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>winning animated feature something everyone ag...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>film sports provocative appealing story thats ...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>entertaining computergenerated hyperrealist an...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  ingenious concept design execution could watch...  2009-10-04 00:00:00   \n",
       "1                             years inventive comedy  2008-08-31 00:00:00   \n",
       "2  winning animated feature something everyone ag...  2008-08-18 00:00:00   \n",
       "3  film sports provocative appealing story thats ...  2008-06-09 00:00:00   \n",
       "4  entertaining computergenerated hyperrealist an...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed text.\n",
    "Finaldf_train = preprocessingText(df_train)\n",
    "Finaldf_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert your data (quotes) into bag-of-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "# define vectorizer\n",
    "X = vectorizer.fit_transform( Finaldf_train.quote.values)\n",
    "# vectorize your data. Note: this creates a sparce matrix,\n",
    "# use .toarray() if you want a dense matrix.\n",
    "words = vectorizer.get_feature_names()\n",
    "# in case you want to see what are the actual words\n",
    "words1 = pd.DataFrame(X.toarray(), columns=words)\n",
    "words1['fresh'] =  Finaldf_train['fresh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>007s</th>\n",
       "      <th>044the</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100plus</th>\n",
       "      <th>101</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwicks</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 20812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0014  007  007s  044the  07  10  100  1000  100plus  101    ...      \\\n",
       "0     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "1     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "2     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "3     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "4     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "5     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "6     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "7     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "8     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "9     0    0     0       0   0   0    0     0        0    0    ...       \n",
       "\n",
       "   zooming  zooms  zorro  zorros  zowie  zucker  zweibel  zwick  zwicks  \\\n",
       "0        0      0      0       0      0       0        0      0       0   \n",
       "1        0      0      0       0      0       0        0      0       0   \n",
       "2        0      0      0       0      0       0        0      0       0   \n",
       "3        0      0      0       0      0       0        0      0       0   \n",
       "4        0      0      0       0      0       0        0      0       0   \n",
       "5        0      0      0       0      0       0        0      0       0   \n",
       "6        0      0      0       0      0       0        0      0       0   \n",
       "7        0      0      0       0      0       0        0      0       0   \n",
       "8        0      0      0       0      0       0        0      0       0   \n",
       "9        0      0      0       0      0       0        0      0       0   \n",
       "\n",
       "   zzzzzzzzz  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "\n",
       "[10 rows x 20812 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorized data\n",
    "words1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Removing columns having numeric names \n",
    "df2 = words1.columns.get_values().tolist()\n",
    "df2 = [i for i in df2 if i.isalpha()]\n",
    "words1 = words1.loc[: , df2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split your work data and target (i.e. the variable fresh) into training and validation chunks (80/20 or so)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "    \n",
    "We have split the data into train and validation set in the first step  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F), and log Pr(R).\n",
    "\n",
    "#### These probabilities are based on the values of fresh alone, not on the words the quotes contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5054459562562571"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unconditional (log) probability that the tomato is fresh\n",
    "\n",
    "logP_F = np.log(sum(words1.fresh == 'fresh')/len(words1))\n",
    "logP_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0265047563022767"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unconditional (log) probability that the tomato is rotten\n",
    "\n",
    "logP_R = np.log(sum(words1.fresh == 'rotten')/len(words1))\n",
    "logP_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. For each word w, compute log Pr(wjF) and log Pr(wjR), the (log) probability that the word is present in a fresh/rotten review. These probabilities can easily be calculated from counts of how many times these words are present for each class. Hint: these computations are based on your BOW-s X. Look at ways to sum along columns in this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# log Pr(wjF)\n",
    "# Probability of a word in a sentence(each row) given it is fresh \n",
    "fresh = words1.apply(lambda x: np.log((sum(x == 1) & sum(words1.fresh == 'fresh')) / sum(words1.fresh == 'fresh')), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the infinity values\n",
    "fresh = fresh.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Converting log Pr(wjF) into a dictionary for key value pair, where the pair represents each word and its log probability.\n",
    "fresh = fresh.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# log Pr(wjR)\n",
    "# Probability of a word in a sentence(each row) given it is rotten \n",
    "rotten = words1.apply(lambda x: np.log(sum((x == 1) & (words1.fresh == 'rotten')) / sum(words1.fresh == 'rotten')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the infinity values\n",
    "rotten = rotten.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# Converting log Pr(wjR) into a dictionary for key value pair, where the pair represents each word and its log probability.\n",
    "rotten = rotten.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. For both destination classes, F and R, compute the log-likelihood that the quote belongs to this class. log-likelihood is what is given inside the brackets in equation (1) on slide 28, and the equations on Schutt \"Doing Data Science\", page 102. In lecture notes it is explained before the email classification example (and in the example too). \n",
    "\n",
    "#### Computing these likelihoods involves sums of the previously computed probabilities, log Pr(wjF), and BOW elements xij. Check out np.apply_along_axis that can be used to apply a function on matrix columns/rows so you can create a fairly good one-liner to compute log-likelihood. Loops are fine too if apply seems too complex, just slower and less compact. Based on the log-likelihoods, predict the class F or R for each quote in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for prediction\n",
    "\n",
    "def lets_predict_fresh(row):\n",
    "    ans = 0\n",
    "    string1 = []\n",
    "    string1.append(row)\n",
    "    z = string1[0].split()\n",
    "\n",
    "    for x in range(len(z)):\n",
    "        ans = ans + fresh.get(z[x],0)\n",
    "        \n",
    "    return (ans + logP_F)\n",
    "\n",
    "def lets_predict_rotten(row):\n",
    "    ans = 0\n",
    "    string1 = []\n",
    "    string1.append(row)\n",
    "    z = string1[0].split()\n",
    "    \n",
    "    for x in range(len(z)):\n",
    "        ans = ans + rotten.get(z[x],0)\n",
    "       \n",
    "    return (ans + logP_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#The log-likelihood that the quote belongs to fresh\n",
    "df_test['predicted_for_fresh'] = df_test['quote'].apply(lambda row : lets_predict_fresh(row))\n",
    "#The log-likelihood that the quote belongs to rotten\n",
    "df_test['predicted_for_rotten'] = df_test['quote'].apply(lambda row : lets_predict_rotten(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Based on the log-likelihoods, predicting the class F or R for each quote in the validation set.\n",
    "\n",
    "# Predicted Final\n",
    "df_test['predicted_final'] = np.where(df_test['predicted_for_fresh'] > df_test['predicted_for_rotten'], 'fresh' , 'rotten' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Print the resulting confusion matrix and accuracy (feel free to use existing libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(df_test['fresh'], df_test['predicted_final'])\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>fresh</th>\n",
       "      <th>rotten</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fresh</td>\n",
       "      <td>951</td>\n",
       "      <td>603</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rotten</td>\n",
       "      <td>675</td>\n",
       "      <td>336</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>1626</td>\n",
       "      <td>939</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  fresh  rotten   All\n",
       "True                          \n",
       "fresh        951     603  1554\n",
       "rotten       675     336  1011\n",
       "All         1626     939  2565"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross tabulation of the data.\n",
    "pd.crosstab(df_test['fresh'], df_test['predicted_final'], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hence accuracy is  0.5017543859649123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "print(\"Hence accuracy is \", accuracy_score(df_test['fresh'], df_test['predicted_final']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it is time to look at your fitted model a little bit closer. NB model probabilities are rather easy to understand and interpret. The task here is to find the best words to predict a fresh, and a rotten review. And we only want to look at words that are reasonably frequent, say more frequent than 30 times in the data.\n",
    "\n",
    "#### 1. Extract from your conditional probability vectors log Pr(wjF) and log Pr(wjR) the probabilities that correspond to frequent words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering only \"fresh\" words\n",
    "fresh_words = words1[words1['fresh'] == 'fresh']\n",
    "fresh_words = fresh_words.drop(['fresh'], axis=1)\n",
    "\n",
    "# calculating the frequency of the words for fresh\n",
    "fresh_words_sum = fresh_words.sum(axis = 0)\n",
    "\n",
    "# sorting the frequency values of the words in descending order\n",
    "freq_word_fresh = fresh_words_sum.sort_values(ascending=False)\n",
    "fresh_review = pd.DataFrame(freq_word_fresh.head(30))\n",
    "fresh_review.rename(columns = {0: 'freq'}, inplace = True)\n",
    "fresh_review = fresh_review.reset_index().rename(columns = {'index' : 'words'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering only \"rotten\" words\n",
    "rotten_words = words1[words1['fresh'] == 'rotten']\n",
    "rotten_words = rotten_words.drop(['fresh'], axis=1)\n",
    "\n",
    "# calculating the frequency of the words for rotten\n",
    "rotten_words_sum = rotten_words.sum(axis = 0)\n",
    "\n",
    "# sorting the frequency values of the words in descending order\n",
    "freq_word_rotten = rotten_words_sum.sort_values(ascending=False)\n",
    "rotten_review = pd.DataFrame(freq_word_rotten.head(30))\n",
    "rotten_review.rename(columns = {0: 'freq'}, inplace = True)\n",
    "rotten_review = rotten_review.reset_index().rename(columns = {'index' : 'words'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the probabilities that correspond to the words with the highest frequency only for Rotten\n",
    "highprob_rotten=[]\n",
    "highprob_rotten_word = []\n",
    "for x in range(len(rotten_review['words'])):\n",
    "    highprob_rotten.append(rotten.get(rotten_review.iloc[x]['words'],0)) \n",
    "    highprob_rotten_word.append(rotten_review['words'][x])\n",
    "    \n",
    "rotten_high_final = pd.DataFrame(highprob_rotten_word , highprob_rotten).reset_index()\n",
    "rotten_high_final = rotten_high_final.rename(columns = {'index' : 'freq' , 0 : 'words'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities that correspond to the words with the highest frequency only for Fresh\n",
    "highprob_fresh=[]\n",
    "highprob_fresh_word = []\n",
    "for x in range(len(fresh_review['words'])):\n",
    "    highprob_fresh.append(fresh.get(fresh_review.iloc[x].words,0))\n",
    "    highprob_fresh_word.append(fresh_review['words'][x])\n",
    "    \n",
    "fresh_high_final = pd.DataFrame(highprob_fresh_word , highprob_fresh).reset_index() \n",
    "fresh_high_final = fresh_high_final.rename(columns = {'index' : 'freq' , 0 : 'words'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find 10 best words to predict F and 10 best words to predict R. Hint: imagine we have a review that contains just a single word. Which word will give the highest weight to the probability the review is fresh? Which one to the likelihood it is rotten?\n",
    "#### Comment your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "    \n",
    "The frequent words - \"time, story, much, and even\" have the log probabilities 0, which give them the highest weight to the probability that the review is fresh. \n",
    "\n",
    "The frequent word \"movie\" has the log probability 0, which gives it the highest weight to the probability that the review if rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-7.135826</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.135826</td>\n",
       "      <td>characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.135826</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-7.273329</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-7.273329</td>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-7.425332</td>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        freq       words\n",
       "11  0.000000        time\n",
       "4   0.000000       story\n",
       "6   0.000000        much\n",
       "7   0.000000        even\n",
       "8  -7.135826      movies\n",
       "13 -7.135826  characters\n",
       "3  -7.135826        like\n",
       "23 -7.273329        work\n",
       "16 -7.273329        made\n",
       "25 -7.425332      little"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 best words for fresh \n",
    "best_ten_fresh = fresh_high_final.sort_values(by = 'freq' , ascending=False).head(10)\n",
    "best_ten_fresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.837904</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.915751</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.595601</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.143089</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.624360</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.634075</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.643856</td>\n",
       "      <td>comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.673604</td>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.683657</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.745496</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq   words\n",
       "0 -2.837904   movie\n",
       "1 -2.915751    film\n",
       "2 -3.595601     one\n",
       "3 -4.143089    like\n",
       "4 -4.624360    good\n",
       "5 -4.634075   story\n",
       "6 -4.643856  comedy\n",
       "7 -4.673604    much\n",
       "8 -4.683657    even\n",
       "9 -4.745496  movies"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 best words for rotten\n",
    "best_ten_rotten = rotten_high_final.sort_values(by = 'freq' , ascending=False).head(10)\n",
    "best_ten_rotten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Print out a few missclassified quotes. Can you understand why these are misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>fresh</th>\n",
       "      <th>rotten</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>951</td>\n",
       "      <td>603</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>675</td>\n",
       "      <td>336</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1626</td>\n",
       "      <td>939</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  fresh  rotten   All\n",
       "True                          \n",
       "fresh        951     603  1554\n",
       "rotten       675     336  1011\n",
       "All         1626     939  2565"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross tabulation of the data.\n",
    "pd.crosstab(df_test['fresh'], df_test['predicted_final'], rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created a misclassfication table where the actual value for fresh and rotten is different from our predicted value. \n",
    "df_misclassification=df_test[(df_test.fresh)!=(df_test.predicted_final)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_for_fresh</th>\n",
       "      <th>predicted_for_rotten</th>\n",
       "      <th>predicted_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>Dennis Lim</td>\n",
       "      <td>rotten</td>\n",
       "      <td>162973</td>\n",
       "      <td>http://www.villagevoice.com/issues/9917/lim2.php</td>\n",
       "      <td>Village Voice</td>\n",
       "      <td>Wilde's script, which has a weakness for mild,...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>13672</td>\n",
       "      <td>Get Real</td>\n",
       "      <td>-30.930014</td>\n",
       "      <td>-32.104628</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10668</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>fresh</td>\n",
       "      <td>162973</td>\n",
       "      <td>http://www.reelviews.net/movies/g/get_real.html</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>In Steven, John, and their friends, Shore give...</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>13672</td>\n",
       "      <td>Get Real</td>\n",
       "      <td>-70.726082</td>\n",
       "      <td>-61.707762</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10669</th>\n",
       "      <td>Manny Farber</td>\n",
       "      <td>rotten</td>\n",
       "      <td>37913</td>\n",
       "      <td>http://www.tnr.com/article/film/91917/tnr-film...</td>\n",
       "      <td>The New Republic</td>\n",
       "      <td>The production, mainly because of Michael Curt...</td>\n",
       "      <td>2012-08-31 00:00:00</td>\n",
       "      <td>19975</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>-29.345052</td>\n",
       "      <td>-30.256631</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>37913</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>All this is good melodrama and fair entertainm...</td>\n",
       "      <td>2011-07-25 00:00:00</td>\n",
       "      <td>19975</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>-24.930014</td>\n",
       "      <td>-38.554595</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>Variety Staff</td>\n",
       "      <td>fresh</td>\n",
       "      <td>37913</td>\n",
       "      <td>http://www.variety.com/review/VE1117793121.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>A class feature, showmanly produced by Jerry W...</td>\n",
       "      <td>2007-10-17 00:00:00</td>\n",
       "      <td>19975</td>\n",
       "      <td>Mildred Pierce</td>\n",
       "      <td>-29.345052</td>\n",
       "      <td>-25.882236</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic   fresh    imdb  \\\n",
       "10667          Dennis Lim  rotten  162973   \n",
       "10668  James Berardinelli   fresh  162973   \n",
       "10669        Manny Farber  rotten   37913   \n",
       "10670                 NaN  rotten   37913   \n",
       "10672       Variety Staff   fresh   37913   \n",
       "\n",
       "                                                    link       publication  \\\n",
       "10667   http://www.villagevoice.com/issues/9917/lim2.php     Village Voice   \n",
       "10668    http://www.reelviews.net/movies/g/get_real.html         ReelViews   \n",
       "10669  http://www.tnr.com/article/film/91917/tnr-film...  The New Republic   \n",
       "10670  http://www.time.com/time/magazine/article/0,91...     TIME Magazine   \n",
       "10672  http://www.variety.com/review/VE1117793121.htm...           Variety   \n",
       "\n",
       "                                                   quote          review_date  \\\n",
       "10667  Wilde's script, which has a weakness for mild,...  2000-01-01 00:00:00   \n",
       "10668  In Steven, John, and their friends, Shore give...  2000-01-01 00:00:00   \n",
       "10669  The production, mainly because of Michael Curt...  2012-08-31 00:00:00   \n",
       "10670  All this is good melodrama and fair entertainm...  2011-07-25 00:00:00   \n",
       "10672  A class feature, showmanly produced by Jerry W...  2007-10-17 00:00:00   \n",
       "\n",
       "        rtid           title  predicted_for_fresh  predicted_for_rotten  \\\n",
       "10667  13672        Get Real           -30.930014            -32.104628   \n",
       "10668  13672        Get Real           -70.726082            -61.707762   \n",
       "10669  19975  Mildred Pierce           -29.345052            -30.256631   \n",
       "10670  19975  Mildred Pierce           -24.930014            -38.554595   \n",
       "10672  19975  Mildred Pierce           -29.345052            -25.882236   \n",
       "\n",
       "      predicted_final  \n",
       "10667           fresh  \n",
       "10668          rotten  \n",
       "10669           fresh  \n",
       "10670           fresh  \n",
       "10672          rotten  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misclassification.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NB with smoothing\n",
    "\n",
    "#### So, now you have your brand-new NB algorithm up and running. As a next step, we add smoothing to it . As our task is to find the best smoothing parameter below, your first task is to mold what you did above into two funcions: one for fitting and another one for predicting.\n",
    "\n",
    "#### 1. Create two functions: one for fitting NB model, and another to predict outcome based on the fitted model. As mentioned above, the model is fully described with 4 probabilities, so your fitting function may return such a list as the model; and the prediction function may take it as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function for pre-processing\n",
    "def preprocessingText1(rotten_tomatoe):\n",
    "\n",
    "    result_df = rotten_tomatoe.drop_duplicates()\n",
    "\n",
    "    result_df['quote'] = ( result_df['quote'].apply(lambda x: \" \".join(x.lower() for x in x.split()))) # everything to lowercase\n",
    "    result_df['quote'] =  result_df['quote'].str.replace('[^\\w\\s]','') # Removes Punctuation\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    result_df['quote'] =  result_df['quote'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    \n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    # define vectorizer\n",
    "    X = vectorizer.fit_transform( result_df.quote.values)\n",
    "    # vectorize your data. Note: this creates a sparce matrix,\n",
    "    # use .toarray() if you want a dense matrix.\n",
    "    words = vectorizer.get_feature_names()\n",
    "    # in case you want to see what are the actual words\n",
    "    words1 = pd.DataFrame(X.toarray(), columns=words)\n",
    "    words1['fresh'] =  result_df['fresh']\n",
    "    \n",
    "    df2 = words1.columns.get_values().tolist()\n",
    "    df2 = [i for i in df2 if i.isalpha()]\n",
    "    words1 = words1.loc[: , df2]\n",
    "    \n",
    "    \n",
    "    return  words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Subhiksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: The 'get_values' method is deprecated and will be removed in a future version. Use '.to_numpy()' or '.array' instead.\n"
     ]
    }
   ],
   "source": [
    "words1 = preprocessingText1(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function to fit the NB model which gives the output as the 4 probabilities\n",
    "\n",
    "def fit(words1, alpha):\n",
    "    \n",
    "    logP_F = np.log((sum(words1.fresh == 'fresh') + alpha)  / (len(words1) + alpha))\n",
    "    print(\"Probability of fresh is \", logP_F)\n",
    "    \n",
    "    logP_R = np.log((sum(words1.fresh == 'rotten') + alpha) / (len(words1) + alpha))\n",
    "    print(\"Probability of rotten is \", logP_R)\n",
    "    \n",
    "    a = sum(words1.fresh == 'fresh')\n",
    "    b = sum(words1.fresh == 'rotten')\n",
    "\n",
    "    # Probability of a word in a sentence(each row) given it is fresh \n",
    "    #fresh = words1.apply(lambda x: np.log2((sum(x == 1) & sum(words1.fresh == 'fresh') + alpha) / (a + alpha)), axis=0)\n",
    "    fresh = words1.apply(lambda x: np.log((sum((x == 1) & (words1.fresh == 'fresh')) + alpha) / (a + alpha)), axis=0)\n",
    "    fresh = fresh.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    fresh = fresh.to_dict()\n",
    "    \n",
    "    \n",
    "    #rotten = words1.apply(lambda x: np.log2((sum(x == 1) & sum(words1.fresh == 'rotten') + alpha) / (b + alpha)), axis=0)\n",
    "    rotten = words1.apply(lambda x: np.log((sum((x == 1) & (words1.fresh == 'rotten')) + alpha) / (a + alpha)), axis=0)\n",
    "\n",
    "    rotten = rotten.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    rotten = rotten.to_dict()\n",
    "    \n",
    "    return logP_F, logP_R, fresh, rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to predict the outcome based on the fitted model.\n",
    "\n",
    "# prediction for fresh\n",
    "def lets_predict_fresh(row):\n",
    "    ans = 0\n",
    "    string1 = []\n",
    "    string1.append(row)\n",
    "    z = string1[0].split()\n",
    "\n",
    "    for x in range(len(z)):\n",
    "        ans = ans + fresh.get(z[x],0)\n",
    "        \n",
    "    return (ans + logP_F)\n",
    "\n",
    "# prediction for rotten\n",
    "def lets_predict_rotten(row):\n",
    "    ans = 0\n",
    "    string1 = []\n",
    "    string1.append(row)\n",
    "    z = string1[0].split()\n",
    "    \n",
    "    for x in range(len(z)):\n",
    "        ans = ans + rotten.get(z[x],0)\n",
    "       \n",
    "    return (ans + logP_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Add smoothing to the model. See Schutt p 103 and 109. Smoothing amounts to assuming that we have \"seen\" every possible word alpha > 0 times already, for both classes. (If you wish, you can also assume you have seen the words alpha times for F and beta times for R). Note that alpha does not have to be an integer, and typically the best alpha < 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "**Adding smoothing to the model by passing Alpha = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of fresh is  -0.5054459562562571\n",
      "Probability of rotten is  -1.0265047563022767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "logP_F, logP_R, fresh, rotten = fit(words1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Purba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Purba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# assigning the probability values to the column predicted_for_fresh\n",
    "df_test['predicted_for_fresh'] = df_test['quote'].apply(lambda row : lets_predict_fresh(row))\n",
    "\n",
    "# assigning the probability values to the column predicted_for_rotten\n",
    "df_test['predicted_for_rotten'] = df_test['quote'].apply(lambda row : lets_predict_rotten(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Purba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Creating a column predicted_final which compares the probability of both fresh and rotten, \n",
    "# and assigns the respective output (fresh/rotten) for each row\n",
    "df_test['predicted_final'] = np.where(df_test['predicted_for_fresh'] > df_test['predicted_for_rotten'], 'fresh' , 'rotten' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hence accuracy is  0.5017543859649123\n"
     ]
    }
   ],
   "source": [
    "# calculating the accuracy\n",
    "print(\"Hence accuracy is \", accuracy_score(df_test['fresh'], df_test['predicted_final']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding smoothing to the model by passing Alpha = 0.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of fresh is  -0.5054331329459061\n",
      "Probability of rotten is  -1.0264698328022848\n"
     ]
    }
   ],
   "source": [
    "logP_F, logP_R, fresh, rotten = fit(words1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_test['predicted_for_fresh'] = df_test['quote'].apply(lambda row : lets_predict_fresh(row))\n",
    "df_test['predicted_for_rotten'] = df_test['quote'].apply(lambda row : lets_predict_rotten(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hence accuracy is  0.6058479532163743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subhiksha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['predicted_final'] = np.where(df_test['predicted_for_fresh'] > df_test['predicted_for_rotten'], 'fresh' , 'rotten' )\n",
    "\n",
    "#calculating the accuracy\n",
    "print(\"Hence accuracy is \", accuracy_score(df_test['fresh'], df_test['predicted_final']) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
